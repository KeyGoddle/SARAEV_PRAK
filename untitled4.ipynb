{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQyDryc+kvOOSaSAjpl9if",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KeyGoddle/SARAEV_PRAK/blob/main/untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deap\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTJ3wxE7sTsQ",
        "outputId": "d08e8dff-ae61-4f22-b791-04736072cde3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deap\n",
            "  Downloading deap-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deap) (1.26.4)\n",
            "Downloading deap-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/135.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: deap\n",
            "Successfully installed deap-1.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzIl2kdLqvqr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from minisom import MiniSom\n",
        "from deap import base, creator, tools, algorithms\n",
        "import random\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST"
      ],
      "metadata": {
        "id": "bImznu-mso9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка MNIST\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Преобразование данных\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Преобразование меток в категориальные данные\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Преобразование изображений в одномерный массив\n",
        "x_train = x_train.reshape(x_train.shape[0], -1)\n",
        "x_test = x_test.reshape(x_test.shape[0], -1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGIKGmPVsOlb",
        "outputId": "54be43b8-482d-418d-91ce-882aeb4e6362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CIFAR-10"
      ],
      "metadata": {
        "id": "M65bt8hnsrZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка CIFAR-10\n",
        "(x_train_cifar, y_train_cifar), (x_test_cifar, y_test_cifar) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Нормализация данных\n",
        "x_train_cifar = x_train_cifar / 255.0\n",
        "x_test_cifar = x_test_cifar / 255.0\n",
        "\n",
        "# Преобразование меток в категориальные данные\n",
        "y_train_cifar = tf.keras.utils.to_categorical(y_train_cifar, 10)\n",
        "y_test_cifar = tf.keras.utils.to_categorical(y_test_cifar, 10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_fQVFdmsmuW",
        "outputId": "40f09d93-37f8-4395-c616-da5703a3ad32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Реализация алгоритма SOM"
      ],
      "metadata": {
        "id": "T6mYg09_stE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_som(x_train, grid_size=10, num_iteration=1000):\n",
        "    # Инициализация SOM\n",
        "    som = MiniSom(grid_size, grid_size, x_train.shape[1], sigma=1.0, learning_rate=0.5)\n",
        "    som.train_random(x_train, num_iteration)\n",
        "\n",
        "    return som\n"
      ],
      "metadata": {
        "id": "NbIQ6hqFst8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Генетический алгоритм для оптимизации гиперпараметров"
      ],
      "metadata": {
        "id": "XIPq8oOmsxAS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tB32lS6JswX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучение и тестирование модели с использованием SOM и генетического алгоритма"
      ],
      "metadata": {
        "id": "ydey_YQbs0Vu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def combined_training(x_train, y_train, x_test, y_test, som_grid_size=10, som_iterations=1000, generations=10, population_size=20):\n",
        "    # Шаг 1: Обучение SOM\n",
        "    som = train_som(x_train, grid_size=som_grid_size, num_iteration=som_iterations)\n",
        "\n",
        "    # Шаг 2: Оптимизация гиперпараметров с использованием генетического алгоритма\n",
        "    best_hyperparameters = optimize_hyperparameters(x_train, y_train, generations=generations, population_size=population_size)\n",
        "\n",
        "    # Шаг 3: Обучение финальной модели с оптимизированными гиперпараметрами\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(best_hyperparameters[0], activation='relu', input_shape=(x_train.shape[1],)))\n",
        "    for _ in range(best_hyperparameters[1]):\n",
        "        model.add(layers.Dense(best_hyperparameters[0], activation='relu'))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_hyperparameters[2]),\n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Обучение модели\n",
        "    model.fit(x_train, y_train, epochs=10, batch_size=64)\n",
        "\n",
        "    # Оценка модели\n",
        "    accuracy = model.evaluate(x_test, y_test)\n",
        "    print(\"Test accuracy:\", accuracy)\n",
        "    return model, accuracy\n"
      ],
      "metadata": {
        "id": "RE-6iOTPs00t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Сравнение с традиционным методом обучения"
      ],
      "metadata": {
        "id": "DTJ_7Hk4s3E6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def traditional_training(x_train, y_train, x_test, y_test):\n",
        "    # Традиционное обучение без SOM и генетического алгоритма\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(64, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(x_train, y_train, epochs=10, batch_size=64)\n",
        "    accuracy = model.evaluate(x_test, y_test)\n",
        "    print(\"Test accuracy (traditional):\", accuracy)\n",
        "    return model, accuracy\n"
      ],
      "metadata": {
        "id": "nk0Y12Kos3kD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Визуализация и выводы"
      ],
      "metadata": {
        "id": "0_Y9EwjFs54V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from minisom import MiniSom\n",
        "from deap import base, creator, tools, algorithms\n",
        "import random\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Загрузка и подготовка данных MNIST\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train / 255.0  # Нормализация\n",
        "x_test = x_test / 255.0    # Нормализация\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)  # Преобразование меток в категории\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], -1)  # Преобразование изображений в одномерный массив\n",
        "x_test = x_test.reshape(x_test.shape[0], -1)      # Преобразование изображений в одномерный массив\n",
        "\n",
        "# Функция для обучения SOM\n",
        "def train_som(x_train, grid_size=10, num_iteration=1000):\n",
        "    som = MiniSom(grid_size, grid_size, x_train.shape[1], sigma=1.0, learning_rate=0.5)\n",
        "    som.train_random(x_train, num_iteration)\n",
        "    return som\n",
        "\n",
        "# Генетический алгоритм для оптимизации гиперпараметров\n",
        "def optimize_hyperparameters(x_train, y_train, generations=10, population_size=20):\n",
        "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "    def evaluate(individual):\n",
        "        model = models.Sequential()\n",
        "        model.add(layers.Dense(individual[0], activation='relu', input_shape=(x_train.shape[1],)))\n",
        "        for _ in range(individual[1]):\n",
        "            model.add(layers.Dense(individual[0], activation='relu'))\n",
        "        model.add(layers.Dense(10, activation='softmax'))\n",
        "        def check_learning_rate(lr):\n",
        "          # Ограничение learning_rate в пределах от 0.0001 до 0.01\n",
        "          return max(0.0001, min(lr, 0.01))\n",
        "\n",
        "        # Применяем проверку на learning_rate\n",
        "        learning_rate = check_learning_rate(individual[2])\n",
        "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                      loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        model.fit(x_train, y_train, epochs=3, batch_size=64, verbose=0)\n",
        "        _, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "        return (accuracy,)\n",
        "\n",
        "    def create_individual():\n",
        "        return [random.randint(32, 128), random.randint(1, 3), random.uniform(0.0001, 0.01)]\n",
        "\n",
        "    toolbox = base.Toolbox()\n",
        "    toolbox.register(\"individual\", tools.initIterate, creator.Individual, create_individual)\n",
        "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "    toolbox.register(\"mate\", tools.cxTwoPoint)\n",
        "    toolbox.register(\"mutate\", tools.mutUniformInt, low=32, up=128, indpb=0.2)\n",
        "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "    toolbox.register(\"evaluate\", evaluate)\n",
        "\n",
        "    population = toolbox.population(n=population_size)\n",
        "    algorithms.eaSimple(population, toolbox, cxpb=0.7, mutpb=0.2, ngen=generations, verbose=True)\n",
        "\n",
        "    best_individual = tools.selBest(population, 1)[0]\n",
        "    return best_individual\n",
        "\n",
        "# Совмещение SOM и генетического алгоритма\n",
        "def combined_training(x_train, y_train, x_test, y_test, som_grid_size=10, som_iterations=1000, generations=10, population_size=20):\n",
        "    som = train_som(x_train, grid_size=som_grid_size, num_iteration=som_iterations)\n",
        "    best_hyperparameters = optimize_hyperparameters(x_train, y_train, generations=generations, population_size=population_size)\n",
        "\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(best_hyperparameters[0], activation='relu', input_shape=(x_train.shape[1],)))\n",
        "    for _ in range(best_hyperparameters[1]):\n",
        "        model.add(layers.Dense(best_hyperparameters[0], activation='relu'))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    def check_learning_rate(lr):\n",
        "        # Ограничение learning_rate в пределах от 0.0001 до 0.01\n",
        "        return max(0.0001, min(lr, 0.01))\n",
        "\n",
        "    # Применяем проверку перед компиляцией модели\n",
        "    learning_rate = check_learning_rate(best_hyperparameters[2])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "    model.fit(x_train, y_train, epochs=10, batch_size=64)\n",
        "    accuracy = model.evaluate(x_test, y_test)\n",
        "    print(\"Test accuracy:\", accuracy)\n",
        "    return model, accuracy\n",
        "\n",
        "# Традиционное обучение\n",
        "def traditional_training(x_train, y_train, x_test, y_test):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(64, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(x_train, y_train, epochs=10, batch_size=64)\n",
        "    accuracy = model.evaluate(x_test, y_test)\n",
        "    print(\"Test accuracy (traditional):\", accuracy)\n",
        "    return model, accuracy\n",
        "\n",
        "# Визуализация результатов\n",
        "def plot_results(accuracy1, accuracy2):\n",
        "    labels = ['SOM + GA', 'Traditional']\n",
        "    accuracies = [accuracy1[1], accuracy2[1]]\n",
        "\n",
        "    plt.bar(labels, accuracies)\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Comparison of Models')\n",
        "    plt.show()\n",
        "\n",
        "# 2. Обучение с использованием SOM и генетического алгоритма на MNIST\n",
        "som_grid_size = 10\n",
        "som_iterations = 1000\n",
        "generations = 10\n",
        "population_size = 20\n",
        "\n",
        "model_som_ga, accuracy_som_ga = combined_training(x_train, y_train, x_test, y_test,\n",
        "                                                  som_grid_size=som_grid_size,\n",
        "                                                  som_iterations=som_iterations,\n",
        "                                                  generations=generations,\n",
        "                                                  population_size=population_size)\n",
        "\n",
        "# 3. Традиционное обучение для сравнения на MNIST\n",
        "model_traditional, accuracy_traditional = traditional_training(x_train, y_train, x_test, y_test)\n",
        "\n",
        "# 4. Визуализация результатов\n",
        "plot_results(accuracy_som_ga, accuracy_traditional)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zHyLbdisvmBQ",
        "outputId": "f6a1459e-62f3-4506-d476-41b4b4372678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gen\tnevals\n",
            "0  \t20    \n",
            "1  \t13    \n",
            "2  \t13    \n",
            "3  \t14    \n",
            "4  \t16    \n",
            "5  \t15    \n",
            "6  \t20    \n",
            "7  \t15    \n",
            "8  \t12    \n",
            "9  \t18    \n",
            "10 \t15    \n",
            "Epoch 1/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8770 - loss: 0.4147\n",
            "Epoch 2/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9698 - loss: 0.0987\n",
            "Epoch 3/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9791 - loss: 0.0672\n",
            "Epoch 4/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9845 - loss: 0.0511\n",
            "Epoch 5/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9861 - loss: 0.0440\n",
            "Epoch 6/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0325\n",
            "Epoch 7/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9912 - loss: 0.0270\n",
            "Epoch 8/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9914 - loss: 0.0262\n",
            "Epoch 9/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9929 - loss: 0.0217\n",
            "Epoch 10/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9947 - loss: 0.0161\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9738 - loss: 0.1137\n",
            "Test accuracy: [0.09574539959430695, 0.9779999852180481]\n",
            "Epoch 1/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8350 - loss: 0.5641\n",
            "Epoch 2/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9526 - loss: 0.1555\n",
            "Epoch 3/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9657 - loss: 0.1141\n",
            "Epoch 4/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9730 - loss: 0.0876\n",
            "Epoch 5/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9772 - loss: 0.0719\n",
            "Epoch 6/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9816 - loss: 0.0586\n",
            "Epoch 7/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9850 - loss: 0.0489\n",
            "Epoch 8/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9863 - loss: 0.0416\n",
            "Epoch 9/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9889 - loss: 0.0354\n",
            "Epoch 10/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9906 - loss: 0.0302\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9686 - loss: 0.1048\n",
            "Test accuracy (traditional): [0.09292248636484146, 0.972000002861023]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "OvdNPVBHBkQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_som_ga.save(\"model_som_ga.h5\")\n",
        "model_traditional.save(\"model_traditional.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmTf3mWeDFPp",
        "outputId": "423116b6-8f8d-45b9-d3c1-2aa17ee44f14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model_som_ga = load_model(\"model_som_ga.h5\")\n",
        "model_traditional = load_model(\"model_traditional.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upo9O1VgDgy2",
        "outputId": "ed1abad1-e85b-4319-bf77-3445615b8d18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_som_ga = model_som_ga.predict(x_test)\n",
        "y_pred_traditional = model_traditional.predict(x_test)\n",
        "\n",
        "y_pred_som_ga_labels = np.argmax(y_pred_som_ga, axis=1)\n",
        "y_pred_traditional_labels = np.argmax(y_pred_traditional, axis=1)\n",
        "y_true_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Classification report and confusion matrix\n",
        "print(\"Classification Report for SOM + GA:\")\n",
        "print(classification_report(y_true_labels, y_pred_som_ga_labels))\n",
        "print(\"Confusion Matrix for SOM + GA:\")\n",
        "print(confusion_matrix(y_true_labels, y_pred_som_ga_labels))\n",
        "\n",
        "print(\"Classification Report for Traditional:\")\n",
        "print(classification_report(y_true_labels, y_pred_traditional_labels))\n",
        "print(\"Confusion Matrix for Traditional:\")\n",
        "print(confusion_matrix(y_true_labels, y_pred_traditional_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CecA7HGSDjL4",
        "outputId": "58c558a5-5afe-4efa-ad6f-d2b6acd5717f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Classification Report for SOM + GA:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98       980\n",
            "           1       0.99      0.99      0.99      1135\n",
            "           2       0.98      0.97      0.98      1032\n",
            "           3       0.97      0.98      0.98      1010\n",
            "           4       0.98      0.98      0.98       982\n",
            "           5       0.98      0.96      0.97       892\n",
            "           6       0.99      0.99      0.99       958\n",
            "           7       0.98      0.97      0.97      1028\n",
            "           8       0.98      0.96      0.97       974\n",
            "           9       0.96      0.98      0.97      1009\n",
            "\n",
            "    accuracy                           0.98     10000\n",
            "   macro avg       0.98      0.98      0.98     10000\n",
            "weighted avg       0.98      0.98      0.98     10000\n",
            "\n",
            "Confusion Matrix for SOM + GA:\n",
            "[[ 971    1    0    1    0    3    1    1    2    0]\n",
            " [   0 1128    2    1    0    1    1    0    2    0]\n",
            " [   3    2 1004    4    5    0    1    8    5    0]\n",
            " [   0    0    2  991    0    3    0    5    0    9]\n",
            " [   3    1    4    1  962    0    3    1    0    7]\n",
            " [   2    1    0   12    2  860    2    1    5    7]\n",
            " [   3    2    0    1    2    3  946    0    1    0]\n",
            " [   3    3   11    3    1    0    0  997    4    6]\n",
            " [   6    0    4    7    2    3    2    4  937    9]\n",
            " [   3    2    0    0   12    1    0    5    2  984]]\n",
            "Classification Report for Traditional:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98       980\n",
            "           1       0.99      0.99      0.99      1135\n",
            "           2       0.96      0.97      0.97      1032\n",
            "           3       0.96      0.97      0.97      1010\n",
            "           4       0.97      0.97      0.97       982\n",
            "           5       0.98      0.96      0.97       892\n",
            "           6       0.98      0.97      0.98       958\n",
            "           7       0.99      0.96      0.97      1028\n",
            "           8       0.94      0.98      0.96       974\n",
            "           9       0.96      0.97      0.96      1009\n",
            "\n",
            "    accuracy                           0.97     10000\n",
            "   macro avg       0.97      0.97      0.97     10000\n",
            "weighted avg       0.97      0.97      0.97     10000\n",
            "\n",
            "Confusion Matrix for Traditional:\n",
            "[[ 957    0    3    2    1    4    5    2    5    1]\n",
            " [   0 1125    3    1    0    0    2    0    4    0]\n",
            " [   3    3 1005    5    1    0    0    1   14    0]\n",
            " [   0    0    7  984    0    5    0    2    9    3]\n",
            " [   1    0    8    1  951    1    3    2    2   13]\n",
            " [   2    1    0    9    2  855    4    0   13    6]\n",
            " [   2    4    3    1    8    2  933    0    5    0]\n",
            " [   1    5   13    9    4    0    0  983    2   11]\n",
            " [   1    1    2    6    0    3    1    3  953    4]\n",
            " [   1    3    0   10   10    0    0    2    9  974]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сравнение метрик\n",
        "1. Accuracy (Точность классификации)\n",
        "SOM + GA: 98% (0.98)\n",
        "Традиционная модель: 97% (0.97)\n",
        "Модель с использованием SOM + GA немного лучше в общей точности.\n",
        "\n",
        "2. Precision, Recall, F1-Score\n",
        "SOM + GA:\n",
        "Precision, Recall и F1-Score для большинства классов близки к 0.98–0.99, что указывает на высокую точность предсказаний для всех классов.\n",
        "Особенно высокая точность для классов 1, 6, и 0.\n",
        "Традиционная модель:\n",
        "Precision и Recall для большинства классов немного ниже (0.96–0.99).\n",
        "Классы 2, 3, и 8 демонстрируют незначительно меньшую точность, чем у модели с SOM + GA.\n",
        "3. Confusion Matrix (Матрица ошибок)\n",
        "SOM + GA:\n",
        "Очень низкий уровень ошибок.\n",
        "Например, для класса 0 модель допустила всего 9 ошибок (всего 980 примеров).\n",
        "Для класса 1 ошибок почти нет.\n",
        "Традиционная модель:\n",
        "Ошибок чуть больше.\n",
        "Например, для класса 0 модель допустила 23 ошибки.\n",
        "Класс 8 демонстрирует относительно больше ошибок в сравнении с SOM + GA.\n",
        "Визуализация матрицы ошибок\n",
        "Матрица ошибок дает возможность понять, где модели совершают ошибки. Например:\n",
        "\n",
        "SOM + GA:\n",
        "Очень точные предсказания для всех классов.\n",
        "Класс 5 показывает небольшие ошибки, путая некоторые примеры с классом 3.\n",
        "Традиционная модель:\n",
        "Более высокий уровень ошибок, особенно для классов 8, 5, и 4.\n",
        "Рекомендации для улучшения:\n",
        "Анализ ошибок:\n",
        "\n",
        "Большинство ошибок в обеих моделях происходит между схожими по визуальному представлению классами, например 3 и 5, или 4 и 9.\n",
        "Можно попробовать использовать архитектуры сверточных нейронных сетей (CNN), чтобы улучшить качество предсказаний для сложных классов.\n",
        "Тонкая настройка гиперпараметров:\n",
        "\n",
        "SOM + GA показала свои преимущества, но можно провести дополнительную оптимизацию параметров SOM и генетического алгоритма для улучшения производительности.\n",
        "Введение новых методов регуляризации:\n",
        "\n",
        "Dropout или Batch Normalization могут помочь традиционной модели справиться с переобучением.\n",
        "Заключение\n",
        "Модель с использованием SOM + GA демонстрирует лучшее качество классификации, чем традиционная модель:\n",
        "\n",
        "Более высокая точность.\n",
        "Более сбалансированные метрики (Precision, Recall, F1-Score).\n",
        "Меньше ошибок, особенно в сложных для классификации классах.\n",
        "Эти результаты подтверждают, что комбинирование методов (SOM для кластеризации и GA для оптимизации) эффективно улучшает производительность модели."
      ],
      "metadata": {
        "id": "VXtL9MelDwaz"
      }
    }
  ]
}